---
title: "Episode 4: Using large language models"
teaching: 
exercises: 
---

:::::: questions 
- What is a large language model
...
::::::

:::::: objectives
At the end of this episodes, the learners will:
- 
::::::

## This episode
- what are we going to discuss in this episode
- which challenges will we tackle
general description

## What are Large Language Models?
- What is an LLM? (explain around ChatGPT since people know that one?)
- What are LLMs good at and what not
-- startup simple chat? (code along, if so, use llama, in which case llama needs to be explained)
- how are they different from other NLP techniques
-- challenge: something with having them try out stuff that does not work? (code)
- how do they work? (how is it that you can chat with the model) -> something (very globally) on the architecture?

## Examples of existing LLMs (gpt, llama, mistral etc.)
- number of existing models (maybe also a timeline)
- which one to chose when
- how do you use an LLM such that you get the best results?
-- what is prompt engineering? (code along)

## Hands on
code along and challenge(s)

collect the data itself

- Collect the titles of the articles.

- Get a one-sentence description of the articles.

- Classify the articles: e.g. politics, economics, sports, culture...

- Compare the writing styles

## Pitfalls, limitations, caveats, privacy


:::::::::::: challenge 



:::::: solution

::::::

::::::::::::


