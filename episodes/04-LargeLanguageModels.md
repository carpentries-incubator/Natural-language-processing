---
title: "Episode 4: Using large language models"
teaching: 
exercises: 
---

:::::: questions 
- What is a Large Language Model (LLM)?
- How do LLMs differ from traditional NLP models?
- What is the Transformer architecture, and why is it important for LLMs?
- How does prompt engineering influence LLM outputs?
- What are some real-world applications of LLMs?
- How can LLMs generate, classify, and summarize text?

...
::::::

:::::: objectives
After following this lesson, learners will be able to:
- Understand what Large Language Models (LLMs) are and their role in NLP
- Explain the Transformer architecture and why it is foundational for LLMs
- Use prompt engineering to generate high-quality text responses
- Perform text classification, summarization, and headline generation with LLMs
- Apply LLMs to real-world tasks like news article analysis
- Explore pre-trained LLMs and experiment with custom tasks
- Evaluate and optimize LLM performance for practical applications
- Understand the impact of LLMs in modern AI and language processing

::::::

## This episode
Large Language Models (LLMs) are hot and a big topic these days, and are continuously in the news. Everybody heard of ChatGPT, many tried it out for a variety of purposes, or else incorporated these tools in their daily work. But what are these models exactly, how do they work 'under the hood', and how can you make use of them in the best possible way?

In this episode, we will:
- Explore these LLMs, which represent a significant advancement in natural language processing (NLP). We will begin by defining what LLMs are and touching on their foundational architecture, particularly the Transformer model, which allows the LLM to understand and generate human-like text. 
- Through practical examples, you will discover how to work with thse models for specific tasks such as text classification, summarization, and content generation. We'll also dive into the concept of prompt engineering, demonstrating how to best frame our queries which can significantly impact the quality of responses generated by LLMs. 
- We'll also discuss real-world applications of LLMs, such as analyzing news articles and generating insights from large amounts of text data. 

This episode aims to equip you with both theoretical knowledge and practical skills, preparing you to harness the power of LLMs in your own projects and applications.

## What are Large Language Models?

- What is an LLM? (explain around ChatGPT since people know that one?)
- What are LLMs good at and what not
-- startup simple chat? (code along, if so, use llama, in which case llama needs to be explained)
- how are they different from other NLP techniques
-- challenge: something with having them try out stuff that does not work? (code)
- how do they work? (how is it that you can chat with the model) -> something (very globally) on the architecture?

## Examples of existing LLMs (gpt, llama, mistral etc.)
- number of existing models (maybe also a timeline)
- which one to chose when
- how do you use an LLM such that you get the best results?
-- what is prompt engineering? (code along)

## Prompt engineering
- Set up OLlama (start up, and download model)
- Explain prompt engineering
- 

## Hands on
code along and challenge(s)

collect the data itself

- Collect the titles of the articles.

- Get a one-sentence description of the articles.

- Classify the articles: e.g. politics, economics, sports, culture...

- Compare the writing styles

## Pitfalls, limitations, caveats, privacy


:::::::::::: challenge 



:::::: solution

::::::

::::::::::::


