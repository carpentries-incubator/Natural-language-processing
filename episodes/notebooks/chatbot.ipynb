{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5cbaff-0c1f-4e7e-a23a-c55f1dc18a74",
   "metadata": {},
   "source": [
    "# Using LLMs in a conversational style\n",
    "\n",
    "This section explores how we can create a simple LLM chat assistant. I.e., to programmatically write a simple chatbot using the [transformers](https://huggingface.co/docs/transformers/v4.17.0/en/installation) Python library to interact with in a conversational style similar to well-known chat assistants such as [ChatGPT](https://chatgpt.com/), [Claude](https://claude.ai/), [Gemini](https://gemini.google.com/app), and [DeepSeek](https://chat.deepseek.com/sign_in)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8cc5eb-b83c-489e-a285-d9bcf7e04c50",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2f0af7-fc1f-4910-be8e-fe48b3ee0bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kodymoodley/Documents/repos/llmtut/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad467a67-4fee-4111-948c-a49cb3afb611",
   "metadata": {},
   "source": [
    "## 2. Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f1aa4d-4837-4ab2-a7bb-eb65514662b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a model (uncomment the one you wish to use)\n",
    "# model_id = \"HuggingFaceTB/SmolLM2-135M\" # base model\n",
    "model_id = \"HuggingFaceTB/SmolLM2-135M-Instruct\" # fine-tuned assistant model\n",
    "# model_id = \"HuggingFaceTB/SmolLM3-3B-Base\" # base model\n",
    "# model_id = \"HuggingFaceTB/SmolLM3-3B\" # fine-tuned assistant model\n",
    "# model_id = \"meta-llama/Llama-3.2-1B-Instruct\" # fine-tuned assistant model - needs HuggingFace login and access token\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# Set pad_token_id to eos_token_id to avoid unncessary warning messages\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f803e055-3449-4c4d-a4a5-b7fd2e27f64d",
   "metadata": {},
   "source": [
    "## 3. Initialise inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb2ae072-aae7-4e19-acb6-3d90cb83c361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Build text-generation inference pipeline\n",
    "chatbot = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36e5aa-af34-4b71-be22-5bcff4d0b6e4",
   "metadata": {},
   "source": [
    "## 4. Create function to generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9858e0d4-b109-4b6b-91c4-d8152827e7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise conversation history (keep track of all messages)\n",
    "history = []\n",
    "\n",
    "# Function to handle chatting (predicting next tokens and returning response)\n",
    "def chat(user_input):\n",
    "    global history\n",
    "    history.append({\"role\": \"user\", \"content\": f\"{user_input}\"})\n",
    "    response = chatbot(history, max_new_tokens=100, do_sample=True, top_k=20, temperature=0.7)[0][\"generated_text\"]\n",
    "    response_text = response[len(response)-1]['content']\n",
    "    history.append({\"role\": \"assistant\", \"content\": f\"{response_text}\"})    \n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02463cb2-012e-460d-bcf9-e131b57f1a99",
   "metadata": {},
   "source": [
    "## 5. Call chatbot interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a480d23-fe0b-458f-b72e-744e251929fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Who is Railen Ackerby?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Railen Ackerby, a remarkable author and author of children's books, is a celebrated author, illustrator, and educator. Born in Wales, Ackerby grew up in a small town in Wales, where he learned to draw early. He later studied art at the Royal School of Art in Wales before moving to the United Kingdom to work as an illustrator and illustrator assistant for children's books.\n",
      "\n",
      "Ackerby's book-length works include \"The Magic Tree House,\" \"D\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simulate chatbot interaction\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\"]: # to exit\n",
    "        break\n",
    "    print(\"Bot:\", chat(user_input))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1754c2-5d7b-4405-bbd5-ee9268c031a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmlesson",
   "language": "python",
   "name": "llmlesson"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
