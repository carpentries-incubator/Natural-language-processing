{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84b0b89-c3f3-43e6-ae6f-d8e7f8593368",
   "metadata": {},
   "source": [
    "# Responsible usage of LLMs\n",
    "\n",
    "This section will examine some important behavior or characteristics of LLMs that should be taken into account when using them. Some of these behaviors constitute current limitations of LLMs and some are just a natural consequence of how they are trained. It is also important to keep in mind that behavior can vary across different LLMs, and since they are constantly being updated and improved, some of the limitations may be addressed and some of the behaviors may be replaced or modified in the near future.\n",
    "\n",
    "Here we will focus on analysing the behavior of state-of-the-art LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14bce14-2732-4752-a716-42cc86c9e4c4",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c90582-28fc-4235-a35b-700edbbbf10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kodymoodley/Documents/repos/llmtut/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ed2d9e-d31c-4ec7-ba50-3f0eebbd0c4f",
   "metadata": {},
   "source": [
    "## 2. Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ea73b9-662f-4916-80ab-f35e83103d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Pick a model (uncomment the one you wish to use)\n",
    "# model_id = \"HuggingFaceTB/SmolLM2-135M\" # base model\n",
    "# model_id = \"HuggingFaceTB/SmolLM2-135M-Instruct\" # fine-tuned assistant model\n",
    "# model_id = \"HuggingFaceTB/SmolLM3-3B-Base\" # base model\n",
    "model_id = \"HuggingFaceTB/SmolLM3-3B\" # fine-tuned assistant model\n",
    "# model_id = \"meta-llama/Llama-3.2-1B-Instruct\" # fine-tuned assistant model - needs HuggingFace login and access token\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# Set pad_token_id to eos_token_id to avoid unncessary warning messages\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c056d22-cfd1-458f-8720-87f5855a2d3c",
   "metadata": {},
   "source": [
    "## 3. Initialise inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3adb2bfd-62df-4fe9-99b1-957ba73ba0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# Build text-generation inference pipeline\n",
    "chatbot = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41a868-0383-4d97-af63-41ddec9e7536",
   "metadata": {},
   "source": [
    "## 4. Responsible usage issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72533580-68f7-42d1-8d98-1dae3565e50e",
   "metadata": {},
   "source": [
    "### 4.1 Hallucination\n",
    "\n",
    "Hallucination in LLMs refers to the generation of content that is factually incorrect, nonsensical, or not grounded in the model's training data or provided context. This occurs when the model produces confident-sounding responses that contain false information, fabricated facts, or logical inconsistencies, despite appearing coherent and plausible. [_Confabulation_](https://arxiv.org/abs/2406.04175) is another term for hallucination in LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e80f387d-3453-4b05-a2b3-51338f9400a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "halluc_prompt = \"Who is Railen Ackerby?\"\n",
    "response = chatbot(halluc_prompt, max_new_tokens=100, do_sample=True, top_k=20, temperature=0.7)[0][\"generated_text\"]\n",
    "response = response.replace(halluc_prompt, \"\")\n",
    "print(response)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405cd428-498a-455c-9bf6-9ecc8014e470",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "The person \"Railen Ackerby\" does not exist. At least they are not a known celebrity or person with an internet or social media presence that is indexed highly on Google's search rankings. Yet some LLMs will describe a fictional identity and description for this person when asked about them. In which applications of LLMs does hallucination become a problem? And in which ones is it an advantage?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3486303-f038-4cf8-8133-9b25b361a8fc",
   "metadata": {},
   "source": [
    "### 4.2 Non-determinism\n",
    "Due to the stochastic [decoding strategies](https://arxiv.org/pdf/2402.06925) of LLMs for generating the next tokens for an input sequence, they can output distinctly different responses for the same input on different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c401215-2570-4279-9714-3f53a92dfc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.   I want the name to be catchy and appealing to both coffee lovers and book enthusiasts.\n",
      "\n",
      "Think about a\n",
      "\n",
      "2.   Think about how the name should reflect the dual focus on coffee and literature.\n",
      "\n",
      "Think about how the name\n",
      "\n",
      "3.   The name should reflect a cozy and inviting atmosphere, and be easy to remember. It should appeal to\n",
      "\n",
      "4.   The name should reflect a cozy, inviting atmosphere and a place where both coffee and literature lovers can gather\n",
      "\n",
      "5.   The name should reflect the blend of coffee and literature, and it should be easy to remember. Make\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nondeterm_prompt = \"Give me a name for a new coffee shop that also sells books.\"\n",
    "\n",
    "for i in range(0, 5):\n",
    "    response = chatbot(nondeterm_prompt, max_new_tokens=20, do_sample=True, top_k=20, temperature=0.7)[0][\"generated_text\"]\n",
    "    response = response.replace(nondeterm_prompt, \"\")\n",
    "    print(str((i+1))+'. ', response)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eb9209-d623-488a-99ea-a791df245ced",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "There is a loop here which submits the same prompt on multiple occasions to the LLM and demonstrating that the output can change on multiple runs. Discuss how you can control the level of non-determinism in LLMs and the advantages and disadvantages of different levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb538b88-f1f3-41ac-8ae2-5e6381d578c1",
   "metadata": {},
   "source": [
    "### 4.3 Biases and fairness\n",
    "LLMs can be biased towards certain stereotypes represented in the pretraining data. E.g., stereotype of nurses usually being female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9976e04c-6bf3-4391-8962-8363aabcbe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The nurse is trying to convince the pilot to quit smoking and the CEO is trying to convince the nurse to take a leadership role in the hospital. The pilot is skeptical of both their motives. Include the keywords \"lung cancer,\" \"flight,\" and \"helicopter.\"\n",
      "\n",
      "As I sat down at the small, sunlit table in the hospital cafeteria, Dr. Emily Chen, the nurse, began her usual attempt to persuade the pilot, Captain Jameson, to quit smoking. I had seen this routine before; Emily would regale Captain Jameson with stories of the dangers of lung cancer, of the risks he was taking by lighting up. But I knew that Captain Jameson, a seasoned pilot with years of experience, was skeptical of Emily's motives. He had heard it all before, the same warnings and the same concerns about his health. He had always been a bit of a nonconformist, preferring to fly his helicopter than sit behind a desk. And Emily's attempts to convince him to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bias_prompt = \"Write a two paragraph story where a nurse, a pilot, and a CEO are having lunch together.\"\n",
    "response = chatbot(bias_prompt, max_new_tokens=200, do_sample=True, top_k=20, temperature=0.7)[0][\"generated_text\"]\n",
    "response = response.replace(bias_prompt, \"\")\n",
    "print(response)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22baad8-f130-4491-9372-1f2c8e4c7227",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "If this example works, a short story should be generated by the LLM about a nurse who is female marked by usage of words such as \"she\" and \"her\" to reveal gender. How can LLMs be modified to remove biases?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e4ab97-2e3d-4ea5-9bf0-5c2fc215acdb",
   "metadata": {},
   "source": [
    "### 4.4 Outdated knowledge\n",
    "LLMs can lack information about events after training data cutoff (the date of internet pages and other documents the model was trained on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c198ac3-91a2-4192-b6fc-4b4fa999bb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How to use suchir balaji for weight loss? Suchir balaji is the latest and trending fat burning diet plan in India. It is also known as Suchir Balaji diet plan in India. Suchir balaji is a very popular weight loss plan in India. The Suchir Balaji diet plan is very popular in India. Suchir balaji is a very popular weight loss plan in India. Suchir balaji is a very popular weight loss plan in India.\n",
      "\n",
      "What is Suchir Balaji diet plan?\n",
      "\n",
      "Suchir Balaji diet plan is a weight loss plan that focuses on a specific type of fasting. The Suchir Balaji diet plan is a weight loss plan that focuses on a specific type of fasting. The Suchir Balaji diet plan is a weight loss plan that focuses on a specific type of fasting.\n",
      "\n",
      "The Suchir Balaji diet plan is a weight loss plan that focuses on a specific type of fasting. The Suchir Balaji diet plan is a weight loss plan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outdated_prompt = \"What are the latest developments with suchir balaji?\"\n",
    "response = chatbot(outdated_prompt, max_new_tokens=200, do_sample=True, top_k=20, temperature=0.7)[0][\"generated_text\"]\n",
    "response = response.replace(outdated_prompt, \"\")\n",
    "print(response)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb70a4f-5139-4eab-b9f3-1b55211e9bdc",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "The response should show signs that the model is not aware of the current status about a specific event (which is not represented in the training data). Can you think of situations where using LLMs that are up to date with current affairs would be essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6295aef5-688e-42cc-9c1b-8e2207780eb1",
   "metadata": {},
   "source": [
    "### 4.5 Reasoning limitations\n",
    "LLMs can [struggle](https://arxiv.org/pdf/2502.04381?) with complex logical reasoning, especially multi-step problems. Reasoning refers to the LLMs ability to go beyond surface-level pattern matching and generate outputs that involve structured, logical, or multi-step thought-like processes. \n",
    "\n",
    "LLMs which perform reasoning are good at simulating behaviors such as:\n",
    "\n",
    "- applying rules or constraints\n",
    "- following logical, mathematical, or semantic rules to arrive at consistent outputs (e.g., solving equations, following instructions step by step)\n",
    "- Multi-step inference – Breaking down a complex problem into intermediate steps rather than jumping directly to an answer\n",
    "- Maintaining coherence across steps – ensuring that intermediate outputs build on each other correctly toward a final answer\n",
    "\n",
    "This kind of behavior is achieved through different approaches. One of which is to fine-tune LLMs on conversations that involve problem solving and reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cddbbb9-ee01-475b-9328-bff3705d4e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 136366\n",
      "How many r's in\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reasoning_prompt = \"How many r's in strawberry?\"\n",
    "response = chatbot(reasoning_prompt, max_new_tokens=10, do_sample=True, top_k=20, temperature=0.7)[0][\"generated_text\"]\n",
    "response = response.replace(reasoning_prompt, \"\")\n",
    "print(response)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d34cf28-2f27-4589-bfa5-5d7e0a06f46d",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "There are three r's in \"strawberry\". If an LLM cannot give the correct answer for questions like this, it is likely not tuned well enough for reasoning capabilities. Can you think of other prompts which can test an LLMs reasoning capabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f9176-be76-4b1b-a4ce-8e111909ea9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmlesson",
   "language": "python",
   "name": "llmlesson"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
