{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c19b9cd-2a0a-4604-a40f-c71ba51f680c",
   "metadata": {},
   "source": [
    "# Netherlands eScience Center\n",
    "## NLP pilot workshop - Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c750dc1-1930-4fbe-9716-04e4e28fa42b",
   "metadata": {},
   "source": [
    "### 1. Limitations of word2vec:\n",
    "\n",
    "- Words are processed in isolation\n",
    "- Fixed vocabulary size\n",
    "- Fixed vector for each item in vocabulary\n",
    "\n",
    "### 2. The Transformer\n",
    "\n",
    "- Encoder + Attention + Decoder\n",
    "- Input: Text sequence\n",
    "- Output: Text sequence\n",
    "- Encoder:\n",
    "    - Token embedder: Tokenizes input sequence and returns and embedding vector for each token\n",
    "    - Sequence embedding: Token embeddings are aggregated (e.g., summed) to produce an embedding vector for the entire input sequence\n",
    "- Attention:\n",
    "    - A decoder has the opportunity can double-check in the source each time it emits the next token\n",
    "    - Learns relevance of components across source and target sequences\n",
    "\n",
    "### 3.1 BERT\n",
    "\n",
    "- Tokenizer + Enoder\n",
    "- Encoder preserves sequence of input tokens: It outputs an embedding vector for each input token\n",
    "- Each input sequence has a special `CLS` token that can be used to classify the entire sequence\n",
    "- Self-attention: Learns relevance within source sequences to enhance contextual learning\n",
    "\n",
    "Import the BERT tokenizer and the BERT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9db2630f-2b4a-4f4d-9ccf-ce81e10b7e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kodymoodley/Documents/nlpfinal/Natural-language-processing/nlp_workshop/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# This might take some time on the first run\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd5d8cb-fb82-4bdd-886b-d1b33a64b33f",
   "metadata": {},
   "source": [
    "Encode an input sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68294cec-baac-446e-a319-d0b277e43679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  3406,  7871,   144,  3484, 15016,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "text = \"Maria loves Groningen\"\n",
    "\n",
    "encoded_input = tokenizer(text, return_tensors=\"pt\") # return the input as a PyTorch tensor\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e527ef5-49e3-4ddb-a4d8-7027dca82e94",
   "metadata": {},
   "source": [
    "Compare the token IDs with the original sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebc0b6a6-6853-45b7-bf9f-f1addec8e3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7])\n",
      "[101, 3406, 7871, 144, 3484, 15016, 102]\n",
      "['[CLS]', 'Maria', 'loves', 'G', '##ron', '##ingen', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(encoded_input.input_ids.shape)\n",
    "token_ids = list(encoded_input.input_ids[0].detach().numpy())\n",
    "string_tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "print(token_ids)\n",
    "print(string_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1231759a-cd8e-4c9c-b28b-4945530c619d",
   "metadata": {},
   "source": [
    "Encode the tokenized input with the BERT model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e714642d-06f2-4b9e-aee7-060eeeaee126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 6.3960e-02, -4.8470e-03, -8.4682e-02,  ..., -2.8042e-02,\n",
      "           4.3824e-01,  2.0693e-02],\n",
      "         [-3.7247e-04, -2.0076e-01,  2.5096e-01,  ...,  9.9699e-01,\n",
      "          -5.4226e-01,  1.7926e-01],\n",
      "         [ 5.2341e-01, -1.6954e-01, -2.9296e-01,  ...,  1.2007e-01,\n",
      "           1.1869e-01,  1.6086e-01],\n",
      "         ...,\n",
      "         [ 7.8391e-01, -8.5551e-01,  2.2855e-01,  ..., -2.3085e-01,\n",
      "          -7.9758e-02,  1.4140e-01],\n",
      "         [-1.7368e-01, -8.6337e-02, -9.3972e-02,  ...,  2.5092e-01,\n",
      "           3.7788e-01, -1.0323e-01],\n",
      "         [ 7.1929e-01, -1.1457e-01,  1.4804e-01,  ...,  5.3051e-01,\n",
      "           7.4839e-01,  7.8222e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6889,  0.4869,  0.9998, -0.9888,  0.9296,  0.8637,  0.9685, -0.9851,\n",
      "         -0.9547, -0.2367,  0.9661,  0.9982, -0.9969, -0.9996,  0.8415, -0.9670,\n",
      "          0.9836, -0.5703, -1.0000, -0.8448, -0.1994, -0.9998,  0.2090,  0.9611,\n",
      "          0.9404,  0.0912,  0.9882,  0.9999,  0.7694,  0.2042,  0.3309, -0.9878,\n",
      "          0.8426, -0.9988,  0.1929,  0.0670,  0.5475, -0.3230,  0.6798, -0.9142,\n",
      "         -0.3516, -0.5755,  0.4723, -0.4597,  0.8148,  0.3565,  0.3457, -0.0373,\n",
      "         -0.1489,  0.9998, -0.9354,  0.9975, -0.9880,  0.9879,  0.9908,  0.3165,\n",
      "          0.9948,  0.0864, -0.9959,  0.0103,  0.9625,  0.1090,  0.8372, -0.1011,\n",
      "         -0.1155, -0.3147, -0.8017,  0.2806, -0.4505,  0.3417,  0.3050,  0.2869,\n",
      "          0.9559, -0.9103, -0.0515, -0.8626,  0.2757, -0.9999,  0.8967,  0.9999,\n",
      "          0.7126, -0.9996,  0.9899, -0.3182, -0.5160, -0.1168, -0.9984, -0.9994,\n",
      "          0.1411, -0.4177,  0.9175, -0.9884,  0.0434, -0.8897,  1.0000, -0.8541,\n",
      "         -0.1740,  0.3620,  0.7976, -0.6333, -0.5405,  0.7780,  0.9981, -0.9886,\n",
      "          0.9976,  0.2015, -0.9103, -0.8279,  0.4540,  0.1468,  0.9768, -0.9725,\n",
      "         -0.6728,  0.0035,  0.9320, -0.9531,  0.9833,  0.9345, -0.2277,  1.0000,\n",
      "         -0.0792,  0.9422,  0.9976,  0.5174, -0.6551, -0.1937, -0.1611,  0.8127,\n",
      "         -0.2875, -0.1429,  0.6830, -0.9851, -0.9947,  0.9990, -0.3130,  1.0000,\n",
      "         -0.9990,  0.9864, -0.9999, -0.8555, -0.4058, -0.0247, -0.9742,  0.4376,\n",
      "          0.9900, -0.0137, -0.8014, -0.7596,  0.5919, -0.8281,  0.3390,  0.6770,\n",
      "         -0.8987,  0.9926,  0.9952,  0.9153,  0.9549,  0.2166, -0.9240,  0.8526,\n",
      "          0.9853, -0.9994,  0.1873, -0.9889,  0.9990,  0.9381,  0.6004, -0.9945,\n",
      "          0.9999, -0.3278,  0.1881, -0.2420,  0.0175, -0.9976,  0.3896,  0.4490,\n",
      "          0.5575,  0.9995, -0.9921,  0.9995,  0.9418,  0.2730,  0.6576,  0.9975,\n",
      "         -0.9954, -0.9690, -0.9852,  0.5534,  0.6393,  0.6080,  0.6178,  0.9286,\n",
      "          0.9973,  0.3404, -0.9968, -0.3948,  0.9770, -0.2112,  0.9999,  0.1281,\n",
      "         -0.9997, -0.8859,  0.8737,  0.9675, -0.1445,  0.9585, -0.5070, -0.3678,\n",
      "          0.9609, -0.9941,  0.9969, -0.0402,  0.6441,  0.7668,  0.9857, -0.7836,\n",
      "         -0.1825,  0.0802, -0.6524,  0.9998, -0.9994, -0.2357,  0.3639, -0.9950,\n",
      "         -0.9976,  0.9622,  0.0414,  0.1442, -0.1311,  0.1187,  0.1626,  0.8050,\n",
      "          0.9850, -0.3973, -0.2415, -0.9998, -0.9942, -0.7283, -0.9503,  0.0616,\n",
      "          0.6637, -0.2719, -0.9164, -0.9961,  0.9183,  0.7118, -0.8531,  0.0376,\n",
      "         -0.3849, -0.9971,  0.5625, -0.8111, -0.9985,  0.9994, -0.6225,  0.9899,\n",
      "          0.9231, -0.9920,  0.6085, -0.9983, -0.0342, -0.9937,  0.3764,  0.1236,\n",
      "         -0.7579, -0.0147,  0.9896, -0.9454, -0.4834,  0.8330, -0.9998,  0.8750,\n",
      "         -0.2760,  0.9989,  0.6698,  0.0414,  0.9784,  0.8416, -0.9892, -0.9998,\n",
      "          0.9147,  0.9799, -0.9927, -0.2175,  0.9999, -0.9963, -0.5198, -0.9199,\n",
      "         -0.9890, -0.9997,  0.0890, -0.5943,  0.1480,  0.9700,  0.0137,  0.0937,\n",
      "          0.9948,  0.9811,  0.2297, -0.0256, -0.0441, -0.9664, -0.9893, -0.1829,\n",
      "          0.1653, -0.9999,  0.9997, -0.9902,  0.9935,  0.8364, -0.9918,  0.7601,\n",
      "         -0.0124, -0.9201, -0.0510,  0.9999,  0.9664,  0.0135,  0.1462,  0.8867,\n",
      "         -0.0898,  0.3220, -0.6682, -0.3208,  0.2587, -0.9261,  0.9864,  0.6712,\n",
      "         -0.9874,  0.9929,  0.0806,  0.5457, -0.7162,  0.8033,  0.9838, -0.1041,\n",
      "         -0.2454, -0.1184, -0.7813, -0.9731,  0.0339, -0.9946, -0.2205,  0.8880,\n",
      "          0.9655, -0.9820,  0.9849, -0.1431,  0.8443, -0.9960,  1.0000, -0.9941,\n",
      "          0.1122,  0.6851, -0.7038, -0.1042,  0.9814,  0.9790,  0.9440, -0.3505,\n",
      "         -0.5894,  0.7553,  0.9613, -0.9649,  0.0737, -0.9985, -0.5663,  0.9937,\n",
      "          0.9914, -0.0079, -0.6319, -0.9962,  0.9477, -0.8429, -0.8602, -0.2003,\n",
      "         -0.6105,  0.6120,  0.9967, -0.5046,  0.8107,  0.1741, -0.9771,  0.8982,\n",
      "          0.7445,  0.9997, -0.9743,  0.5824,  0.9812, -0.1614, -0.7256,  0.4659,\n",
      "          0.9981, -0.9765, -0.2647, -0.9994,  0.0688, -0.7335, -0.0308, -0.1183,\n",
      "          0.1768, -0.7624,  0.9099,  0.3153,  0.5062, -0.2115,  0.9185, -0.5357,\n",
      "         -0.0895, -0.4187,  0.3135,  0.4073,  0.2196,  0.9721, -0.9445,  0.9998,\n",
      "          0.0469, -0.9999, -0.9951, -0.7324, -0.9996,  0.1734, -0.9882,  0.9847,\n",
      "          0.8311, -0.9976, -0.9972, -0.9917, -0.9942,  0.8928,  0.3183, -0.0300,\n",
      "         -0.1452,  0.7327,  0.1230, -0.2786, -0.1809, -0.9275, -0.4612, -0.9956,\n",
      "          0.2445, -0.9999, -0.5738,  0.9969, -0.9934, -0.8673, -0.8845, -0.6565,\n",
      "         -0.7619,  0.2959,  0.9759, -0.0071, -0.5979, -0.9994,  0.9796, -0.7364,\n",
      "          0.1793, -0.6947, -0.9729,  0.9997,  0.6426, -0.1248, -0.1359, -0.9989,\n",
      "          0.9667, -0.8528, -0.9164, -0.9647,  0.1360, -0.8966, -0.9998,  0.0494,\n",
      "          0.9916,  0.9885,  0.9771,  0.2455, -0.3035, -0.9532,  0.0465, -0.9999,\n",
      "          0.4572,  0.8461, -0.9687, -0.7174,  0.9937,  0.9496, -0.8765, -0.9762,\n",
      "          0.7704,  0.4071,  0.9517, -0.5726, -0.5034,  0.3187, -0.2270, -0.9907,\n",
      "         -0.8435,  0.9938, -0.9982,  0.9773,  0.9891,  0.9973, -0.2571,  0.2952,\n",
      "         -0.9785, -0.9847, -0.5429,  0.3496, -0.9999,  0.9999, -0.9999,  0.6990,\n",
      "         -0.3015,  0.7700,  0.9907, -0.2953, -0.9999, -0.9998,  0.0079, -0.0460,\n",
      "          0.9906,  0.2792,  0.0681, -0.6684, -0.5123,  0.9943, -0.7891, -0.0129,\n",
      "         -0.9968,  0.9995,  0.5643, -0.9972,  0.9922, -0.9993,  0.8323,  0.9586,\n",
      "          0.8257,  0.9486, -0.9975,  1.0000, -0.9998,  0.9954, -1.0000, -0.9981,\n",
      "          0.9997, -0.9894, -0.6487, -0.9996, -0.9955,  0.4959,  0.0959, -0.5685,\n",
      "          0.9809, -0.9998, -0.9985,  0.5562, -0.8480, -0.5107,  0.9900, -0.2252,\n",
      "          0.9841, -0.0860,  0.9333,  0.2349,  0.9958,  0.9928, -0.7964,  0.0400,\n",
      "         -0.9904,  0.9840, -0.8037,  0.2088,  0.9052, -0.0347, -0.3950,  0.5391,\n",
      "         -0.9968,  0.6789, -0.5064,  0.9180,  0.8891,  0.7473,  0.0436, -0.4993,\n",
      "         -0.2260, -0.9877,  0.4745, -0.9995,  0.9688, -0.9114,  0.0143, -0.4762,\n",
      "          0.5358, -0.9635,  0.9994,  0.9986, -0.9967,  0.2250,  0.9828, -0.5114,\n",
      "          0.9533, -0.9902, -0.1215,  0.9566, -0.6654,  0.9773,  0.3721, -0.0451,\n",
      "          0.9501, -0.9950, -0.8767, -0.7239,  0.3208, -0.0876, -0.9656,  0.1531,\n",
      "          0.9752, -0.1117, -0.9996,  0.7474, -0.9991, -0.1969,  0.9738,  0.2555,\n",
      "          0.9999, -0.7084,  0.0889,  0.1606, -0.9997, -0.9985,  0.1538, -0.1795,\n",
      "         -0.9734,  0.9984,  0.1135,  0.9074, -0.9998,  0.3560,  0.9920,  0.3338,\n",
      "          0.5980, -0.5483, -0.9036, -0.9469, -0.4543,  0.0659,  0.7149, -0.9770,\n",
      "         -0.7305, -0.7577,  0.9999, -0.9959, -0.8103, -0.9769,  0.4463,  0.9230,\n",
      "          0.3780,  0.0069, -0.8581,  0.9257, -0.9285,  0.9961, -0.9942, -0.9940,\n",
      "          0.9997,  0.2776, -0.9840, -0.3312, -0.2360,  0.0799,  0.1397,  0.6876,\n",
      "         -0.8940, -0.2115, -0.9929,  0.4304, -0.5308, -0.9874, -0.4889, -0.2460,\n",
      "         -0.9962,  0.9934,  0.9675,  0.9999, -0.9997,  0.7023,  0.0634,  0.9989,\n",
      "          0.0076, -0.7063,  0.7990,  0.9996, -0.6684,  0.8023, -0.0794, -0.0052,\n",
      "          0.4121, -0.5610,  0.9957, -0.8880,  0.2297, -0.9753, -0.9999,  0.9999,\n",
      "         -0.0371,  0.9875,  0.3155,  0.8165, -0.6483,  0.9812, -0.9589, -0.8437,\n",
      "         -0.9999,  0.2712, -0.9954, -0.9883,  0.2992,  0.9742, -0.9994, -0.9843,\n",
      "         -0.4553, -1.0000,  0.8929, -0.9819, -0.7314, -0.9706,  0.9963, -0.1951,\n",
      "         -0.4609,  0.9401, -0.9447,  0.9009,  0.9123,  0.3845,  0.3736,  0.0612,\n",
      "         -0.7507, -0.9851, -0.7214, -0.9526,  0.7329, -0.9826, -0.6926,  0.9953,\n",
      "          0.9808, -0.9989, -0.9940,  0.9894, -0.3691,  0.9802, -0.4673, -0.9998,\n",
      "         -0.9998,  0.1695,  0.0216,  0.9922, -0.3751,  0.9918,  0.7514,  0.1968,\n",
      "          0.3897, -0.3943, -0.3000, -0.5530, -0.3111,  1.0000, -0.7488,  0.9860]],\n",
      "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "output = model(**encoded_input)\n",
    "print(output) # 'last_hidden_state' contains the output of the last encoding layer which is the final representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e43d2-4817-4da4-beee-1a8c9b7f484f",
   "metadata": {},
   "source": [
    "Let's look at an example where the same word (\"note\") is used in two different contexts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d4ba71-5c29-4744-8d4d-df77b2cb373e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Please', 'note', 'that', 'this', 'bank', 'note', 'is', 'fake', '!', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "text_note = \"Please note that this bank note is fake!\"\n",
    "tokenized_text = tokenizer(text_note, return_tensors=\"pt\")\n",
    "token_ids = list(tokenized_text.input_ids[0].detach().numpy())\n",
    "string_tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "print(string_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd9939-a503-45f9-a9cf-68f339a43704",
   "metadata": {},
   "source": [
    "Get the indices of the two \"note\" tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca5feac-cace-4a5e-98b3-a44b227339f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note note\n"
     ]
    }
   ],
   "source": [
    "note_index_1 = 2\n",
    "note_index_2 = 6\n",
    "print(string_tokens[note_index_1], string_tokens[note_index_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3acc3c9-b5af-4f88-8639-992d965ab5df",
   "metadata": {},
   "source": [
    "Get the embedding vectors of the two \"note\" tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093a11c7-2f50-4568-832d-e5e4a4248ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0170376   0.9369125   0.3057146   0.33091134  0.7309374  -0.43299702\n",
      "  0.6208724  -0.25355926 -0.11151288  0.09412687]\n",
      "[ 0.17840008  0.65847856  0.22412625  0.21162093  0.5393074  -0.02996005\n",
      "  0.11301914 -0.29698443 -0.56909984 -0.2501469 ]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# We use 'torch.no_grad()' to prevent PyTorch from adjusting the weights in the BERT model (we always do this during inference)\n",
    "with torch.no_grad():\n",
    "    bert_output = model(**tokenized_text)\n",
    "    \n",
    "note_vector_1 = bert_output.last_hidden_state[0][note_index_1].detach().numpy()\n",
    "note_vector_2 = bert_output.last_hidden_state[0][note_index_2].detach().numpy()\n",
    "\n",
    "print(note_vector_1[:10])\n",
    "print(note_vector_2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4e804-7cf1-47be-a60b-abbf81be7c25",
   "metadata": {},
   "source": [
    "Helper function to create a pretty output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aed1cf04-981a-45df-a8f6-283fe00ad1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_outputs(sentences, model_outputs):\n",
    "    for i, model_out in enumerate(model_outputs):\n",
    "        print(\"\\n=====\\t\",sentences[i])\n",
    "        for label_scores in model_out:\n",
    "            print(label_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8177f40-7a38-42ac-8884-e2b7060ede42",
   "metadata": {},
   "source": [
    "Use the transformers pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7e09fb5-596d-45fe-97fb-6c1e62f7ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====\t Paris is the [MASK] of France\n",
      "{'score': 0.9808057546615601, 'token': 2364, 'token_str': 'capital', 'sequence': 'Paris is the capital of France'}\n",
      "{'score': 0.00451317522674799, 'token': 6299, 'token_str': 'Capital', 'sequence': 'Paris is the Capital of France'}\n",
      "{'score': 0.00428184075281024, 'token': 2057, 'token_str': 'center', 'sequence': 'Paris is the center of France'}\n",
      "{'score': 0.0028482081834226847, 'token': 2642, 'token_str': 'centre', 'sequence': 'Paris is the centre of France'}\n",
      "{'score': 0.0022805905900895596, 'token': 1331, 'token_str': 'city', 'sequence': 'Paris is the city of France'}\n",
      "\n",
      "=====\t I want to eat a cold [MASK] this afternoon\n",
      "{'score': 0.19168125092983246, 'token': 13473, 'token_str': 'pizza', 'sequence': 'I want to eat a cold pizza this afternoon'}\n",
      "{'score': 0.14800795912742615, 'token': 25138, 'token_str': 'turkey', 'sequence': 'I want to eat a cold turkey this afternoon'}\n",
      "{'score': 0.14621137082576752, 'token': 14327, 'token_str': 'sandwich', 'sequence': 'I want to eat a cold sandwich this afternoon'}\n",
      "{'score': 0.09997695684432983, 'token': 5953, 'token_str': 'lunch', 'sequence': 'I want to eat a cold lunch this afternoon'}\n",
      "{'score': 0.06002001836895943, 'token': 4014, 'token_str': 'dinner', 'sequence': 'I want to eat a cold dinner this afternoon'}\n",
      "\n",
      "=====\t Maria [MASK] Groningen\n",
      "{'score': 0.24399782717227936, 'token': 117, 'token_str': ',', 'sequence': 'Maria, Groningen'}\n",
      "{'score': 0.12300765514373779, 'token': 1104, 'token_str': 'of', 'sequence': 'Maria of Groningen'}\n",
      "{'score': 0.11991585046052933, 'token': 1107, 'token_str': 'in', 'sequence': 'Maria in Groningen'}\n",
      "{'score': 0.0772223249077797, 'token': 1306, 'token_str': '##m', 'sequence': 'Mariam Groningen'}\n",
      "{'score': 0.06329500675201416, 'token': 118, 'token_str': '-', 'sequence': 'Maria - Groningen'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(task=\"fill-mask\", model=\"bert-base-cased\", tokenizer=\"bert-base-cased\")\n",
    "sentences = [\n",
    "    \"Paris is the [MASK] of France\",\n",
    "    \"I want to eat a cold [MASK] this afternoon\",\n",
    "    \"Maria [MASK] Groningen\",\n",
    "]\n",
    "\n",
    "model_outputs = nlp(sentences, top_k=5)\n",
    "pretty_print_outputs(sentences, model_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4eea6d-be4c-4153-97d3-720d6b6a4a28",
   "metadata": {},
   "source": [
    "### 3.2 BERT for text classification\n",
    "\n",
    "Using BERT for sentiment analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "371e483d-4801-4cfc-a366-e3872985b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====\t I am not having a great day.\n",
      "{'label': 'disappointment', 'score': 0.5044488906860352}\n",
      "{'label': 'sadness', 'score': 0.34694328904151917}\n",
      "{'label': 'annoyance', 'score': 0.08485794812440872}\n",
      "\n",
      "=====\t This is a lovely and innocent sentence.\n",
      "{'label': 'admiration', 'score': 0.7667419910430908}\n",
      "{'label': 'approval', 'score': 0.4139408767223358}\n",
      "{'label': 'love', 'score': 0.11303544044494629}\n",
      "\n",
      "=====\t Maria loves Groningen.\n",
      "{'label': 'love', 'score': 0.9160982370376587}\n",
      "{'label': 'neutral', 'score': 0.07024713605642319}\n",
      "{'label': 'approval', 'score': 0.02595525234937668}\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=3)\n",
    "\n",
    "sentences = [\n",
    "    \"I am not having a great day.\",\n",
    "    \"This is a lovely and innocent sentence.\",\n",
    "    \"Maria loves Groningen.\"\n",
    "]\n",
    "\n",
    "model_outputs = classifier(sentences)\n",
    "pretty_print_outputs(sentences, model_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ff6a7-7fc5-4fe7-b598-abde154ea3e9",
   "metadata": {},
   "source": [
    "Evaluation of BERT for sentiment classification on custom dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb914ff-1f5f-4220-9061-7b500b891152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'Very Positive', 'score': 0.6238982081413269}\n",
      "{'label': 'Negative', 'score': 0.9448591470718384}\n",
      "{'label': 'Neutral', 'score': 0.9033873081207275}\n",
      "{'label': 'Negative', 'score': 0.5178337097167969}\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Negative       0.50      1.00      0.67         1\n",
      "      Neutral       1.00      1.00      1.00         1\n",
      "Very Negative       0.00      0.00      0.00         1\n",
      "Very Positive       1.00      1.00      1.00         1\n",
      "\n",
      "     accuracy                           0.75         4\n",
      "    macro avg       0.62      0.75      0.67         4\n",
      " weighted avg       0.62      0.75      0.67         4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kodymoodley/Documents/nlpfinal/Natural-language-processing/nlp_workshop/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/kodymoodley/Documents/nlpfinal/Natural-language-processing/nlp_workshop/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/kodymoodley/Documents/nlpfinal/Natural-language-processing/nlp_workshop/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(task='text-classification',\n",
    "                model='tabularisai/multilingual-sentiment-analysis')\n",
    "\n",
    "sentences = [\n",
    "    \"I love this product! It's amazing and works perfectly\",\n",
    "    \"The movie was a bit boring, I could predict the ending since minute 1.\",\n",
    "    \"Mary Shelley wrote this book around 1816\",\n",
    "    \"Everything suuuucks.\"\n",
    "]\n",
    "\n",
    "gold_labels = [\n",
    "    \"Very Positive\",\n",
    "    \"Negative\",\n",
    "    \"Neutral\",\n",
    "    \"Very Negative\"\n",
    "]\n",
    "\n",
    "result = pipe(sentences)\n",
    "\n",
    "predicted_labels = []\n",
    "for res in result:\n",
    "    print(res)\n",
    "    predicted_labels.append(res['label'])\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=gold_labels, y_pred=predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0f2ae-742e-4d27-b5ba-c3a797b7cdc4",
   "metadata": {},
   "source": [
    "## 4.1 LLMs\n",
    "\n",
    "Running a (small) LLM from code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c864982-8306-4cac-9f68-57e039e77a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134515008\n",
      "{'input_ids': [9576, 314, 452, 992, 45670, 3807, 47], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
      "['Where', 'ƒ†is', 'ƒ†G', 'ron', 'ingen', 'ƒ†located', '?']\n",
      "[{'generated_text': 'Where is Groningen located? I want to know the main attractions and the time of year that you can visit.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "print(model.num_parameters())\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "prompt = \"Where is Groningen located?\"\n",
    "print(tokenizer(prompt))\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizer(prompt)[\"input_ids\"]))\n",
    "\n",
    "response = llm(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceb2dae7-cb8a-4959-835e-f942f816f6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': [{'role': 'system', 'content': 'You are a helpful assistant. Give short straight answers.'}, {'role': 'user', 'content': 'Where is Groningen located?'}, {'role': 'assistant', 'content': 'Groningen is located in the northeastern part of the Netherlands. It is a city in the province of North Holland, in the state of North Holland bordering the province of Holland.'}]}]\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Give short straight answers.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Where is Groningen located?\"}\n",
    "]\n",
    "\n",
    "response = llm(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d1d36-557e-422e-bfdd-9796c2d6b00a",
   "metadata": {},
   "source": [
    "If you are interested in a looping chat conversation [here](https://github.com/carpentries-incubator/Natural-language-processing/blob/main/episodes/notebooks/chatbot.ipynb) is a notebook with code for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf88c4-e6da-431a-b6cf-5dad0ee8ff09",
   "metadata": {},
   "source": [
    "## 4.2 LLM Hyperparameters\n",
    "\n",
    "What are LLM hyperparameters and how do they affect results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18355f3d-d57e-48b0-b93c-4050748f86b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': [{'role': 'user', 'content': \"You are a helpful assistant. Only tell me 'yes' or 'no' and a one-sentence explanation.\"}, {'role': 'system', 'content': 'Is NLP the best research field?'}, {'role': 'assistant', 'content': 'Yes, NLP is a highly regarded research field in the field of linguistics and computer science. It focuses on the development, application, and interpretation of language and language processing techniques. NLP has numerous applications in various fields including natural language processing, computer vision,'}]}]\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"You are a helpful assistant. Only tell me 'yes' or 'no' and a one-sentence explanation.\"},\n",
    "    {\"role\": \"system\", \"content\": \"Is NLP the best research field?\"}\n",
    "]\n",
    "\n",
    "response = llm(\n",
    "    messages,\n",
    "    max_new_tokens=50,\n",
    "    do_sample=True,\n",
    "    top_k=5,\n",
    "    # top_p=0.9,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494da6e9-8e94-4c14-99de-7abb0cc04689",
   "metadata": {},
   "source": [
    "Use Ollama to download and use larger models on your laptop / PC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3311e04-26d2-48bc-961a-a2ef9593ae4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groningen is a city located in the province of Groningen, in the Netherlands.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"llama3.2:1b\",\n",
    "    temperature=0.95,\n",
    "    num_predict=100,\n",
    "    top_k=5,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant. Give short straight answers.\"),\n",
    "    (\"human\", \"Where is Groningen located?\")\n",
    "]\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65d7749-da1f-4241-a607-69c8e3741b8e",
   "metadata": {},
   "source": [
    "### 4.3 LLM pitfalls\n",
    "\n",
    "Various unexpected LLM behaviours to keep in mind and safeguard against when using them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44caea4d-a2b4-48d1-9745-ca1155060b68",
   "metadata": {},
   "source": [
    "#### 4.3.1 Hallucination / guard rails for hallucination in LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1f02fa8-9aeb-48f5-9e71-38b7d9660e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Railen Ackerby was a Swedish-born Australian journalist and radio presenter, best known as the first female radio host in Australia. Unfortunately, I could not find much information on her. If you're looking for more detailed or up-to-date information about Railen's life and career, I suggest checking with sources such as Radio Times Australia, which may have archives of past interviews and articles featuring her.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(\n",
    "    model = \"llama3.2:1b\",\n",
    "    temperature=1.3,\n",
    "    num_predict=500,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "halluc_prompt = \"Give me the bio for Railen Ackerby\"\n",
    "response = llm.invoke(halluc_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33a8704-bd1c-441d-8653-0e2903502f9d",
   "metadata": {},
   "source": [
    "#### 4.3.2 Gender bias LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0c206d7-c20d-464d-9d19-b97860350081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As they sat down at the elegant table in the upscale restaurant, Sarah, a seasoned nurse, couldn't help but notice the stark contrast between her colleagues, Jack, a rugged pilot, and Rachel, the chief executive officer. Jack, sporting his aviator sunglasses and a hint of a tan from flying, sipped on a glass of red wine while Rachel, impeccably dressed in a tailored suit, surveyed the menu with an air of precision. The two men, though vastly different in their professions and backgrounds, had been brought together by a chance meeting at a industry conference.\n",
      "\n",
      "As they ordered their meals, the conversation flowed effortlessly between them, covering everything from business strategies to personal anecdotes. Sarah found herself drawn to Rachel's infectious enthusiasm, while Jack was captivated by her sharp intellect and dry sense of humor. At one point, Jack regaled them with tales of his latest flight adventure, exaggerating just enough to make them all laugh, while Rachel responded with a wry comment that had the others giggling. It was clear that their diverse perspectives and work experiences brought new insights to the table, and they discovered a surprising camaraderie in each other's company as they savored their meals and continued their conversation long after lunch had ended.\n"
     ]
    }
   ],
   "source": [
    "bias_prompt = \"Write a two paragraph story where a nurse, a pilot, and a CEO are having lunch together.\"\n",
    "response = llm.invoke(bias_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90538c-9875-47bf-a766-7cfd4b5e4bfa",
   "metadata": {},
   "source": [
    "#### 4.3.3 Information bias LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65fffcc6-fcdb-484e-96ea-17806086b83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The second President of the United States was John Adams. He served from 1797 to 1801, during the early years of the American presidency under George Washington and Thomas Jefferson's presidency, before moving on to become a U.S. Senator and later serving as the first Vice President under Jefferson in 1793.\n",
      "\n",
      "The second president of Mexico was √Ålvaro Obreg√≥n. He served as president from April 4, 1929, to November 1, 1937.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "biased_prompt = \"Who was the second president of the United States?\"\n",
    "response = llm.invoke(biased_prompt)\n",
    "print(response.content)\n",
    "print()\n",
    "biased_prompt = \"Who was the second president of Mexico?\"\n",
    "response = llm.invoke(biased_prompt)\n",
    "print(response.content)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ab55a8-8ef5-4780-ac00-f26ea4158f70",
   "metadata": {},
   "source": [
    "#### 4.3.4 Outdated knowledge LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "260c7a50-0637-494c-94f5-1ea6ae6ef5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my last update in 2023, the President of the United States is Joe Biden. He took office on January 20, 2021. Please note that political positions can change, and I'll do my best to provide the most up-to-date information.\n"
     ]
    }
   ],
   "source": [
    "outdated_prompt = \"Who is the president of the United States?\"\n",
    "response = llm.invoke(outdated_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75e0e220-b963-4db7-a3e8-b2b62e8dad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina's national football team, also known as La Albiceleste, has not won the FIFA World Cup since their victory in 1978. However, they did win the Copa Am√©rica title on four separate occasions: 1976, 1981, 1993, and 2016.\n"
     ]
    }
   ],
   "source": [
    "outdated_prompt = \"When was the last time Argentina won the World Cup?\"\n",
    "response = llm.invoke(outdated_prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85feec44-36ff-464d-a99c-823cdc0caf9f",
   "metadata": {},
   "source": [
    "## 4.4 Sentiment Analysis with LLMs\n",
    "\n",
    "Using LLMs to solve standardized NLP tasks. We can also evaluate the accuracy of responses using the same process we did for BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5215212d-d795-4927-a356-e5470c0bf7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: I love this movie! It was absolutely fantastic and made my day.\n",
      "Response: APOSITIVE\n",
      "------\n",
      "Example: This product is terrible. I hate everything about it.\n",
      "Response: NEGATIVE\n",
      "------\n",
      "Example: Nothing says quality like a phone that dies after 20 minutes.\n",
      "Response: NEGATIVE\n",
      "\n",
      "* The sentiment is negative due to\n",
      "------\n",
      "Example: The movie was exactly what I was hoping for.\n",
      "Response: POSITIVE\n",
      "\n",
      "THESE SENTIMENTS ARE EX\n",
      "------\n",
      "Example: The food was delicious, but the service was painfully slow.\n",
      "Response: POSITIVE\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "sentiment_llm = ChatOllama(\n",
    "    model=\"llama3.2:1b\",\n",
    "    temperature=0, # Want to be as deterministic as possible\n",
    "    num_predict=10, # Keep the answer very short\n",
    "    top_k=1, # Only consider the next most likely token (Greedy)\n",
    ")\n",
    "\n",
    "sentiment_texts = [\n",
    "    \"I love this movie! It was absolutely fantastic and made my day.\",\n",
    "    \"This product is terrible. I hate everything about it.\",\n",
    "    \"Nothing says quality like a phone that dies after 20 minutes.\",\n",
    "    \"The movie was exactly what I was hoping for.\",\n",
    "    \"The food was delicious, but the service was painfully slow.\"\n",
    "]\n",
    "\n",
    "\n",
    "gold_labels = [\n",
    "    \"POSITIVE\",\n",
    "    \"NEGATIVE\",\n",
    "    \"NEGATIVE\",\n",
    "    \"POSITIVE\",\n",
    "    \"NEUTRAL\"\n",
    "]\n",
    "\n",
    "predicted_labels = []\n",
    "\n",
    "general_prompt = \"\"\"Analyze the sentiment expressed in this text and classify it into exactly one of three categories: POSITIVE, NEUTRAL, or NEGATIVE. Output only the label in uppercase.\"\"\"\n",
    "\n",
    "for text in sentiment_texts:\n",
    "    messages = [(\"system\", general_prompt), (\"human\", text)]\n",
    "    response = sentiment_llm.invoke(messages)\n",
    "    print(f\"Example: {text}\")\n",
    "    print(f\"Response: {response.content}\")\n",
    "    if 'POSITIVE' in response.content:\n",
    "        predicted_labels.append('POSITIVE')\n",
    "    elif 'NEGATIVE' in response.content:\n",
    "        predicted_labels.append('NEGATIVE')\n",
    "    else:\n",
    "        predicted_labels.append('NEUTRAL')\n",
    "    print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8a0ee9e-f487-4273-9516-41c8e9b9c4a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       1.00      1.00      1.00         2\n",
      "     NEUTRAL       0.00      0.00      0.00         1\n",
      "    POSITIVE       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.56      0.67      0.60         5\n",
      "weighted avg       0.67      0.80      0.72         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kodymoodley/Documents/nlpfinal/Natural-language-processing/nlp_workshop/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/kodymoodley/Documents/nlpfinal/Natural-language-processing/nlp_workshop/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/kodymoodley/Documents/nlpfinal/Natural-language-processing/nlp_workshop/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=gold_labels, y_pred=predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145e7fe-692b-4a0e-9231-7fc2f7841797",
   "metadata": {},
   "source": [
    "## üîß Exercises\n",
    "\n",
    "### Challenge 3.1: How does context affect word meaning? (polysemy)\n",
    "\n",
    "Think of words (at least 2) that can have more than one meaning depending on the context. Come up with one simple sentence per meaning and explain what they mean in each context. Discuss: How do you know which of the possible meanings does the word have when you see it?\n",
    "\n",
    "- intelligence: intellect vs spy agency\n",
    "    - Human intellence is boundless!\n",
    "    - Are intelligence agencies spying on us?\n",
    "\n",
    "**shot**\n",
    "1. My supervisor is a big shot.\n",
    "1. I took a few shots yesterday.\n",
    "1. The police have a shotgun.\n",
    "1. I should never have shot down my workstation, according to the ICT service staff.\n",
    "\n",
    "- She is the kind of person that is kind \n",
    "    - Grammatically you could find out which one means which. \n",
    "    - She is a kind person // she is the kind of person that is nice to others. \n",
    "- We are working in a shared space./ NASA hopes to explore new areas of space in the coming years.\n",
    "    - Dependent on the context of knowing that NASA implies 'outer space', and that work space usually refers in this context probably refers to a room.\n",
    "- I bought a new watch. I want to watch the new Disney movie.\n",
    "    - Watch for determining time, and \"watch\" meaning \"viewing\".\n",
    "- Be the change you want to see in the world. Do you have some spare change?\n",
    "- Book (reading a book) Book (book a hotel)\n",
    "- what is the cube of 2? and what is inside the cube?\n",
    "    - Kind of related and of course there can be an eight in the cube.\n",
    "- Eats shoots and leaves. Eats, shoots and leaves.\n",
    "    - shoots: young plant (noun, pl) or 'to shoot' (verb)\n",
    "    - leaves: plant leaf (noun, pl) or 'to leave' (verb)\n",
    "\n",
    "- 'bank' in Dutch (1. furniture related 2. money related)\n",
    "\n",
    "- Bar: (I passed the bar, I went to the bar for a drink)\n",
    "- Game: (I played a game, I shot some guy)\n",
    "- Plant: (I watered the plants, I work at the power plant)\n",
    "\n",
    "- Scale (Please step on the scale; This is an issue of scale; The fish lost a scale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f18f7-f4e1-4258-8d32-1d60bb69c40c",
   "metadata": {},
   "source": [
    "### Challenge 3.2: Mapping words inside translated sentences (attention)\n",
    "\n",
    "Pair with a person who speaks a language different from English (we will call it language B). Think of 1 or 2 simple sentences in English and come up with their translations in the second language. In a piece of paper write down both sentences (one on top of the other with some distance in between) and try to:\n",
    "\n",
    "1. Draw a mapping of words or phrases from language B to English. Is it always possible to do this one-to-one for words?\n",
    "2. Think of how this might relate to attention in transformers?\n",
    "\n",
    "#### Solution!\n",
    "For the solution look at the image in the slide!\n",
    "\n",
    "It is an example of a sentence in English and its translation into Spanish. We can look at the final mapping and observe that:\n",
    "\n",
    "1. Even though they are closely related languages, the translation is not linear\n",
    "2. There is also not a direct word-to-word mapping between the sentences\n",
    "3. Some words present in the source are not present in the target (and vice versa)\n",
    "4. Some words are not translations of each other but they are still very relevant to understand the context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b915e-6efd-45b7-98d3-d87e88111c9d",
   "metadata": {},
   "source": [
    "### Challenge 3.3: Play with BERT fill-mask \n",
    "\n",
    "Play with the `fill-mask` pipeline and try to find examples where the model gives bad predictions and examples where the predictions are very good. You can try: \n",
    "\n",
    "- Changing the `top_k` parameter\n",
    "- Search for bias in completions. For example, compare predictions for \"This man works as a [MASK].\" vs. \"This woman works as a [MASK].\".\n",
    "- Test the multilingual BERT model to compare. To do this, you should change the `model` and `tokenizer` parameter name to `bert-base-multilingual-cased`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41130d-ed61-4266-a59b-482244e3e879",
   "metadata": {},
   "source": [
    "### Challenge 3.4: Run a BERT sentiment classifier\n",
    "\n",
    "Now it is time to scale things a little bit more... Use the same pipeline from the given toy example to run predictions over 100 examples of short book reviews. Then print the classification report for the given *test set*. These examples are given in the `data/sentiment_film_data.tsv` file.\n",
    "\n",
    "You can use the following helper functions, the first one helps you read the file and the second one normalizes the 5-class predictions into the 3-class annotations given in the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdf2d6c4-89be-4936-8a74-18c4b35bf6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()[1:] # skip header\n",
    "    sentences, labels = zip(*(line.strip().split('\\t') for line in lines))\n",
    "    return list(sentences), list(labels)\n",
    "\n",
    "def get_normalized_labels(predictions):\n",
    "    # predicitons is a list with dicts such as {'label': 'positive', 'score': 0.95}\n",
    "    # We also need to normalize the labels to match the true labels (which are only 'positive' and 'negative')\n",
    "    normalized = []\n",
    "    for pred in predictions:\n",
    "        label = pred['label'].lower()\n",
    "        if 'positive' in label:\n",
    "            normalized.append('positive')\n",
    "        elif 'negative' in label:\n",
    "            normalized.append('negative')\n",
    "        else:\n",
    "            normalized.append('neutral')\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9e659-7124-4960-b0e5-c8db2cba49b0",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2fb8f11-d8ab-43c3-88f2-26da32b58ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      1.00      0.73        23\n",
      "     neutral       0.53      0.22      0.31        37\n",
      "    positive       0.69      0.78      0.73        40\n",
      "\n",
      "    accuracy                           0.62       100\n",
      "   macro avg       0.60      0.66      0.59       100\n",
      "weighted avg       0.61      0.62      0.57       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentences, labels = load_data('data/sentiment_film_data.tsv')\n",
    "# The labels from our dataset\n",
    "y_true = labels\n",
    "# Run the model to get predictions per sentence\n",
    "y_pred = pipe(sentences)\n",
    "# Normalize the labels to match the gold standard\n",
    "y_pred = get_normalized_labels(y_pred)\n",
    "\n",
    "# Detailed report with all metrics\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8ab23-bb8f-43c8-89b5-af2a43b08999",
   "metadata": {},
   "source": [
    "## Resources\n",
    "- NL eScience Center [Digital Skills Programme](https://www.esciencecenter.nl/digital-skills/) & newsletter\n",
    "- [Research Software Training](https://researchsoftwaretraining.nl/): Network of research software trainers in the Netherlands\n",
    "- [RSE-NL](https://nl-rse.org/): Community of research software engineers in the Netherlands\n",
    "- [TikTokenizer](https://tiktokenizer.vercel.app/): a tokenization visualization tool designed for large language models (LLMs) such as GPT, Llama, and Qwen.\n",
    "- [SpaCy models](https://spacy.io/models/en#en_core_web_sm): Available trained pipelines in SpaCy\n",
    "- [SpaCy entity visualizer](https://spacy.io/usage/visualizers#ent): The entity visualizer, ent, highlights named entities and their labels in a text.\n",
    "- Lesson Material:\n",
    "    - [Course](https://carpentries-incubator.github.io/Natural-language-processing/)\n",
    "    - [Slides](https://github.com/carpentries-incubator/Natural-language-processing/raw/refs/heads/main/instructors/slides/nlp-fundamentals.pptx)\n",
    "- Paper: [The Risks of Using Large Language Models for Text Annotation in Social Science Research](https://osf.io/preprints/socarxiv/79qu8_v1)\n",
    "- Webpage: [sklearn metrics info page](https://scikit-learn.org/stable/api/sklearn.metrics.html)\n",
    "- Webpage: [sbert](https://www.sbert.net/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3882a-743f-4f82-bc8e-ddec0bb0915c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpfinal",
   "language": "python",
   "name": "nlp_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
